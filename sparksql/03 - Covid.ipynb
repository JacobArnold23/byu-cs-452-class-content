{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTogu7y3WuMV"
      },
      "outputs": [],
      "source": [
        "# Setup Spark SQL\n",
        "# Note if running locally you need the JVM https://www.oracle.com/java/technologies/downloads/\n",
        "# Consider running in https://colab.research.google.com/\n",
        "%pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zjIATulWuMX"
      },
      "outputs": [],
      "source": [
        "# Initialize Context - this is where you'd setup information about your Hadoop cluster if you had one!\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Covid\").getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext\n",
        "\n",
        "sc.setLogLevel(\"WARN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0c_HeLoEWuMY"
      },
      "outputs": [],
      "source": [
        "# Download 100mb covid county data file\n",
        "!curl \"https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv\" > ./uscounties.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLqqsUF4WuMY"
      },
      "outputs": [],
      "source": [
        "# Read the file into a Spark DataFrame\n",
        "usCountiesFilePath = \"./uscounties.csv\"\n",
        "\n",
        "df = spark.read.csv(usCountiesFilePath, inferSchema=True, header=True)\n",
        "\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJZ0D9BSWuMY"
      },
      "outputs": [],
      "source": [
        "# SparkSQL API\n",
        "df.createOrReplaceTempView(\"covid\")  # create table that you can do sql on\n",
        "\n",
        "print(\"Max deaths:\")\n",
        "spark.sql(\n",
        "    \"\"\"\n",
        "    select county, state, deaths\n",
        "    from covid\n",
        "    order by deaths desc\n",
        "    limit 1\n",
        "  \"\"\"\n",
        ").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Un4dLr7SWuMY"
      },
      "outputs": [],
      "source": [
        "# DataFrame style\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "print(\"Max deaths:\")\n",
        "print(\n",
        "    df.orderBy(col(\"deaths\").desc()).take(  # .where(col(\"county\") == \"New York City\") \\\n",
        "        1\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Tnf9daUWuMZ"
      },
      "outputs": [],
      "source": [
        "# RDD MapReduce Style without key\n",
        "rows = df.rdd\n",
        "\n",
        "\n",
        "def getMax(cumm, other):\n",
        "    if other[\"deaths\"] is not None and other[\"deaths\"] > cumm[\"deaths\"]:\n",
        "        return other\n",
        "    else:\n",
        "        return cumm\n",
        "\n",
        "\n",
        "print(\"Max deaths:\")\n",
        "print(rows.reduce(getMax))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Niq8SodKWuMZ"
      },
      "outputs": [],
      "source": [
        "# RDD MapReduce Style with mapped tuples\n",
        "rows = df.rdd\n",
        "\n",
        "\n",
        "def getMax(cumm, other):\n",
        "    if other[0] > cumm[0]:\n",
        "        return other\n",
        "    else:\n",
        "        return cumm\n",
        "\n",
        "\n",
        "rows = rows.map(lambda r: (r[\"deaths\"] or 0, f\"{r['county']},{r['state']}\"))\n",
        "print(\"Max deaths:\")\n",
        "print(rows.reduce(getMax))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ag3VUpo9WuMZ"
      },
      "outputs": [],
      "source": [
        "# Write code to find the county with the most deaths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASwuQqrnWuMZ"
      },
      "outputs": [],
      "source": [
        "# Write code to find the county with the most cases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xEfrgZ4WuMZ"
      },
      "outputs": [],
      "source": [
        "# Write code to find the total number of deaths in Utah county"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTbHRoiLWuMZ"
      },
      "outputs": [],
      "source": [
        "# Write code to find the death rate for each state and sort the states by death rate descending"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2pPvp5VWuMZ"
      },
      "outputs": [],
      "source": [
        "# Write code to something else interesting with this data â€“ your choice"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extra Credit 1 - Plot your death rate data!\n",
        "# Extra Credit 2 - Join this with other data or find something intresting in this data and plot it on a map!\n",
        "\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "data = pd.DataFrame({\n",
        "  'state': ['NY', 'CA', 'TX', 'FL'],\n",
        "  'values': [10, 20, 15, 25]\n",
        "})\n",
        "\n",
        "fig = px.choropleth(\n",
        "    data,\n",
        "    locations='state', # Column with state abbreviations\n",
        "    locationmode='USA-states', # Set location mode to US states\n",
        "    color='values', # Column to determine color intensity\n",
        "    scope='usa', # Limit map to the USA\n",
        "    color_continuous_scale='Viridis', # Choose a color scale\n",
        "    title='Extra Credit Plot <Insert name here>'\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "HASapzHvXF5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IjH6Dq8saDY8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}