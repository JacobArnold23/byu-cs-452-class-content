{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will tell you your current IP address from google colab\n",
    "!curl api.ipify.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install needed python packages\n",
    "%pip install pymongo\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download us-counties.csv\n",
    "!curl -L \"https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv\" > us-counties.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "\n",
    "user = \"YOUR USER\" # Your user from your mongodb project\n",
    "password = \"YOUR PASSWORD\"\n",
    "connectionUrl = f\"mongodb+srv://{user}:{password}@cluster0.4hkmhjv.mongodb.net/\"\n",
    "client = pymongo.MongoClient(connectionUrl)\n",
    "print(f\"Ping result: {client.admin.command('ping')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or get your DB\n",
    "db_name = \"CS452_Mongo_Covid\"\n",
    "db = client.get_database(db_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark SQL Rewrite in MongoDB 1-6\n",
    "\n",
    "*Redo the SparkSQL assignment in MongoDB using the aggregation pipeline.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Write code to define the schema and then read in the dataset\n",
    "#    (took me 17 minutes!!!)\n",
    "\n",
    "import pandas\n",
    "\n",
    "# Load the CSV file\n",
    "df = pandas.read_csv('./us-counties.csv')\n",
    "data = df.to_dict('records')\n",
    "db.casesdeaths.drop()\n",
    "db.casesdeaths.insert_many(data)\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Write code to find the county with the most deaths\n",
    "\n",
    "res = db.casesdeaths.find({},{\"_id\":0, \"state\":1, \"county\":1, \"deaths\":1}).sort({\"deaths\":-1}).limit(1)\n",
    "list(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Write code to find the county with the most cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Write code to find the total number of deaths in Utah county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Write code to find the death rate for each state and sort the states by death rate descending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Write code to something else interesting with this data â€“ your choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this next part we will get experience using MongoDB's aggegregation pipeline's $lookup stage to join collections in MongoDb. Specifically we'll join to our **cases/deaths data** with **[vaccination data](https://ourworldindata.org/us-states-vaccinations#what-share-of-the-population-has-completed-the-initial-vaccination-protocol)** and **[total population data](https://www2.census.gov/programs-surveys/popest/datasets/2010-2019/counties/totals/co-est2019-alldata.csv)**.  First we need to download and ingest the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the CSV for covid vaccination data\n",
    "!curl -L \"https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/vaccinations/us_state_vaccinations.csv\" > \"./us_state_vaccinations.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the vaccinations data into the the DB  (took me 37 seconds)\n",
    "with open(\"./us_state_vaccinations.csv\") as f:\n",
    "  dataRows = csv.DictReader(f)\n",
    "  db.vaccinations.insert_many(dataRows)\n",
    "\n",
    "df = pandas.read_csv('./us_state_vaccinations.csv')\n",
    "data = df.to_dict('records')\n",
    "db.vaccinations.drop()\n",
    "db.vaccinations.insert_many(data)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the total population (Use POPESTIMATE2019)\n",
    "!curl -L \"https://www2.census.gov/programs-surveys/popest/datasets/2010-2019/counties/totals/co-est2019-alldata.csv\" > \"./co-est2019-alldata.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put population data into the DB (took me 10 seconds)\n",
    "# with open(\"./co-est2019-alldata.csv\", encoding='latin-1') as f:\n",
    "#   dataRows = csv.DictReader(f)\n",
    "#   db.population.insert_many(dataRows)\n",
    "\n",
    "df = pandas.read_csv('./co-est2019-alldata.csv', encoding='latin-1')\n",
    "data = df.to_dict('records')\n",
    "db.populations.drop()\n",
    "db.populations.insert_many(data)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the aggregation pipeline and the \\$out stage create a new dataset that just maps the state to total counts. Do this for all three data sets so you have:\n",
    "\n",
    "casesdeaths_state = (state, cases, deaths)\n",
    "\n",
    "populations_state = (state, population)\n",
    "\n",
    "vaccinations_state = (state, vaccinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the casesdeaths_state collection (remember the counties have a running sum by date, taking the max of each county, then summing by state is correct math)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the populations_state collection (this dataset is interesting in that there is a \"county 0\" in each state that represents the state population total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vaccinations_state collection (this dataset is by state and date. You don't want the sum of all the dates, as the data is a running sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the \\$lookup stage of the aggregation pipeline to join your three data sets by state. Note this won't be a perfect join - to find out why look at the states or even the count of states in each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report the state, infection rate (cases/population), death rate (deaths/population), vaccination rate (vaccinated_people/population). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is there a correlation between infection or death rates with the vaccination rate for each state?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask an interesting question that might be answered with this dataset and answer it."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
